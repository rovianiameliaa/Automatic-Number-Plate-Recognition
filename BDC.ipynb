{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install easyocr library\n",
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnarBLMR0p6F",
        "outputId": "63dee475-c3de-40ab-b8f0-9375649516e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.15.2+cu118)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.7.0.72)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (8.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post4)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->easyocr) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easyocr) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easyocr) (16.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5wljiv10n5Z"
      },
      "outputs": [],
      "source": [
        "#Load required libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import cv2\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract the training and testing data\n",
        "train_zip_url = 'https://github.com/rovianiameliaa/SatriaData/raw/main/Data_Train.zip'\n",
        "test_zip_url = 'https://github.com/rovianiameliaa/SatriaData/raw/main/Data_Test.zip'\n",
        "urllib.request.urlretrieve(train_zip_url, 'Data_Train.zip')\n",
        "urllib.request.urlretrieve(test_zip_url, 'Data_Test.zip')\n",
        "\n",
        "train_zip_ref = zipfile.ZipFile('Data_Train.zip', 'r')\n",
        "train_zip_ref.extractall('data_train')\n",
        "\n",
        "test_zip_ref = zipfile.ZipFile('Data_Test.zip', 'r')\n",
        "test_zip_ref.extractall('data_test')\n",
        "test_zip_ref.close()"
      ],
      "metadata": {
        "id": "RW3ZQiCI1FUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test data from Excel files\n",
        "train_excel_url = 'https://github.com/rovianiameliaa/SatriaData/raw/main/DataTrain.xlsx'\n",
        "urllib.request.urlretrieve(train_excel_url, 'DataTrain.xlsx')\n",
        "train_df = pd.read_excel('DataTrain.xlsx')\n",
        "print(train_df)\n",
        "\n",
        "test_excel_url = 'https://github.com/rovianiameliaa/SatriaData/raw/main/DataTest.xlsx'\n",
        "urllib.request.urlretrieve(test_excel_url, 'DataTest.xlsx')\n",
        "test_df = pd.read_excel('DataTest.xlsx')\n",
        "print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7W7rwSV1M9h",
        "outputId": "83962fc6-c82c-48ae-9716-e5bf3543af86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Unnamed: 0 Vehicleregistrationplate        NameofFile\n",
            "0             0                    A7814    DataTrain1.png\n",
            "1             1                  B1074QO    DataTrain2.png\n",
            "2             2                  B1031QO    DataTrain3.png\n",
            "3             3                  B187EDA    DataTrain4.png\n",
            "4             4                  B1089VD    DataTrain5.png\n",
            "..          ...                      ...               ...\n",
            "795         795                 B1677EJC  DataTrain796.png\n",
            "796         796                  B1743VO  DataTrain797.png\n",
            "797         797                 AD1416YD  DataTrain798.png\n",
            "798         798                 AB5419TN  DataTrain799.png\n",
            "799         799                 AB6315SE  DataTrain800.png\n",
            "\n",
            "[800 rows x 3 columns]\n",
            "    Unnamed: 0     Name of File\n",
            "0            0    DataTest1.png\n",
            "1            1    DataTest2.png\n",
            "2            2    DataTest3.png\n",
            "3            3    DataTest4.png\n",
            "4            4    DataTest5.png\n",
            "..         ...              ...\n",
            "95          95   DataTest96.png\n",
            "96          96   DataTest97.png\n",
            "97          97   DataTest98.png\n",
            "98          98   DataTest99.png\n",
            "99          99  DataTest100.png\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the training data\n",
        "train_images =[]\n",
        "train_labels = []\n",
        "train_image_dir = 'data_train'\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_index = index + 1\n",
        "    image_path = os.path.join(train_image_dir, f'DataTrain{image_index}.png')\n",
        "    image = cv2.imread(image_path)\n",
        "    train_images.append(image)\n",
        "    train_labels.append(row['Vehicleregistrationplate'])\n",
        "\n",
        "# Prepare the testing data\n",
        "test_images = []\n",
        "test_image_dir = 'data_test'\n",
        "test_filenames = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_index = index + 1\n",
        "    image_path = os.path.join(test_image_dir, f'DataTest{image_index}.png')\n",
        "    image = cv2.imread(image_path)\n",
        "    test_images.append(image)\n",
        "    test_filenames.append(f\"DataTest{image_index}.png\")"
      ],
      "metadata": {
        "id": "Ot-gKkLN1Ovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "# Calculate the number of plate classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Define a function to preprocess and perform character segmentation on images\n",
        "def perform_character_segmentation(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Convert image to 8-bit unsigned integer\n",
        "    binary = np.uint8(binary)\n",
        "\n",
        "    # Apply connected component analysis\n",
        "    connectivity = 8\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity, cv2.CV_32S)\n",
        "\n",
        "    # Extract individual character images\n",
        "    segmented_characters = []\n",
        "    for i in range(1, num_labels):\n",
        "        x, y, w, h, area = stats[i]\n",
        "        if area > 100:  # Filter out small components\n",
        "            character = image[y:y+h, x:x+w]\n",
        "            segmented_characters.append(character)\n",
        "\n",
        "    return segmented_characters"
      ],
      "metadata": {
        "id": "ERsBzcRh1P1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Model Architecture\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Preprocess the training images\n",
        "train_characters = []\n",
        "train_labels_extended = []\n",
        "for i in range(len(train_images)):\n",
        "    image = train_images[i]\n",
        "    characters = perform_character_segmentation(image)\n",
        "    label = train_labels[i]\n",
        "    for character in characters:\n",
        "        resized_character = cv2.resize(character, (224, 224))  # Resize character image to a fixed shape\n",
        "        train_characters.append(resized_character)\n",
        "        train_labels_extended.append(label)\n",
        "\n",
        "train_characters = np.array(train_characters)\n",
        "train_labels_extended = np.array(train_labels_extended)\n",
        "\n",
        "# Convert the training data to TensorFlow tensors\n",
        "train_characters = tf.convert_to_tensor(train_characters)\n",
        "train_labels_extended = tf.convert_to_tensor(train_labels_extended)\n",
        "\n",
        "# Create an image data generator with augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Generate augmented training data batches\n",
        "train_generator = datagen.flow(train_characters, train_labels_extended, batch_size=128)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, batch_size=64, epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12S0KJmk1RmZ",
        "outputId": "25b8f5da-d831-4bfb-ff44-7907a55bf254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 73s 2s/step - loss: 5.9986 - accuracy: 0.0337\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 5.2285 - accuracy: 0.0618\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 4.7439 - accuracy: 0.0967\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 4.3447 - accuracy: 0.1356\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 3.8548 - accuracy: 0.1842\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 3.5261 - accuracy: 0.2191\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 3.0910 - accuracy: 0.2648\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 2.8323 - accuracy: 0.3058\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 2.5478 - accuracy: 0.3503\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 2.4143 - accuracy: 0.3620\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 2.2004 - accuracy: 0.3977\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.9890 - accuracy: 0.4354\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.8681 - accuracy: 0.4551\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.7239 - accuracy: 0.4932\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.5223 - accuracy: 0.5470\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 1.4196 - accuracy: 0.5742\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.2341 - accuracy: 0.6220\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.2921 - accuracy: 0.5951\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.1897 - accuracy: 0.6437\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.0478 - accuracy: 0.6709\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 1.0883 - accuracy: 0.6601\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.9629 - accuracy: 0.6990\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.9520 - accuracy: 0.7018\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.7289 - accuracy: 0.7713\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.7965 - accuracy: 0.7496\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.7349 - accuracy: 0.7568\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.6852 - accuracy: 0.7797\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.6763 - accuracy: 0.7817\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.6063 - accuracy: 0.8030\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.5764 - accuracy: 0.8138\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.5853 - accuracy: 0.8046\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.5294 - accuracy: 0.8262\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.5059 - accuracy: 0.8307\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.5044 - accuracy: 0.8339\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.5166 - accuracy: 0.8258\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.4063 - accuracy: 0.8632\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.4068 - accuracy: 0.8704\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.4855 - accuracy: 0.8367\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.4803 - accuracy: 0.8463\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.3784 - accuracy: 0.8752\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.3478 - accuracy: 0.8864\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.3142 - accuracy: 0.8969\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.4582 - accuracy: 0.8640\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.4127 - accuracy: 0.8604\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.3148 - accuracy: 0.8965\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.2893 - accuracy: 0.8981\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.3432 - accuracy: 0.8832\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 37s 2s/step - loss: 0.2809 - accuracy: 0.9057\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.3236 - accuracy: 0.8977\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 38s 2s/step - loss: 0.3314 - accuracy: 0.8921\n",
            "10/10 [==============================] - 2s 92ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the testing images\n",
        "test_characters = []\n",
        "for image in test_images:\n",
        "    if image is not None:\n",
        "        characters = perform_character_segmentation(image)\n",
        "        for character in characters:\n",
        "            resized_character = cv2.resize(character, (224, 224))\n",
        "            test_characters.append(resized_character)\n",
        "    else:\n",
        "        print(\"Empty image found!\")\n",
        "\n",
        "test_characters = np.array(test_characters)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = model.predict(test_characters)\n",
        "\n",
        "# Translate the predictions into labels\n",
        "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
        "\n",
        "# Filter out empty or unsuccessful predictions\n",
        "valid_predictions = []\n",
        "valid_filenames = []\n",
        "\n",
        "for i in range(len(predicted_labels)):\n",
        "    if i < len(test_filenames) and test_characters[i] is not None:  # Memastikan indeks valid dan gambar tidak kosong atau gagal diproses\n",
        "        valid_predictions.append(predicted_labels[i])\n",
        "        valid_filenames.append(test_filenames[i])\n",
        "\n",
        "# Create a DataFrame with the valid filenames and predicted labels\n",
        "result_df = pd.DataFrame({'Name of File': valid_filenames, 'Vehicleregistrationplate': valid_predictions})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "result_df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "6JIQbXDwxO7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}